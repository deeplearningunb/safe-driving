{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renan/.local/lib/python3.8/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from unicodedata import normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Dropout\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accent_remover(x):\n",
    "    try:\n",
    "        float(x)\n",
    "        return x\n",
    "    except:\n",
    "        return normalize('NFKD',x).encode('ASCII', 'ignore').decode('ASCII')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (1,2,3,4,7,8,9,10,11,12,13,14,15,16,17,28,29,30,31,32,33) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# Importar dataset\n",
    "dataset = pd.read_csv('datasets/datatran2017.csv', sep= ',', encoding='ISO-8859-1').dropna().drop_duplicates()\n",
    "dataset = dataset.transform([accent_remover])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Com Vitimas Feridas' 'Plena Noite' 'Decrescente' 'Garoa/Chuvisco'\n",
      "  'Simples' 'Reta']\n",
      " ['Com Vitimas Feridas' 'Plena Noite' 'Decrescente' 'Chuva' 'Simples'\n",
      "  'Nao Informado']\n",
      " ['Com Vitimas Fatais' 'Plena Noite' 'Decrescente' 'Ceu Claro' 'Simples'\n",
      "  'Curva']\n",
      " ...\n",
      " ['Com Vitimas Fatais' 'Anoitecer' 'Decrescente' 'Nublado' 'Simples'\n",
      "  'Curva']\n",
      " ['Com Vitimas Feridas' 'Plena Noite' 'Crescente' 'Nublado' 'Simples'\n",
      "  'Reta']\n",
      " ['Com Vitimas Feridas' 'Anoitecer' 'Crescente' 'Nublado' 'Dupla' 'Reta']]\n",
      "[16  8  7 ... 30  8 13]\n"
     ]
    }
   ],
   "source": [
    "# Pega as dados das colunas:\n",
    "# data_inversa\tdia_semana\thorario\tuf\tbr\tkm\tcondicao_metereologica\tlatitude\tlongitude\n",
    "X = dataset.iloc[:, 11:17].values\n",
    "y = dataset.iloc[:, 22].values\n",
    "y=np.array(y)\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 1 2 2 5]\n",
      " [1 2 1 1 2 3]\n",
      " [0 2 1 0 2 0]\n",
      " ...\n",
      " [0 1 1 6 2 0]\n",
      " [1 2 0 6 2 5]\n",
      " [1 1 0 6 0 5]]\n",
      "[[0.0 1.0 0.0 ... 0.0 2 5]\n",
      " [0.0 1.0 0.0 ... 0.0 2 3]\n",
      " [1.0 0.0 0.0 ... 0.0 2 0]\n",
      " ...\n",
      " [1.0 0.0 0.0 ... 0.0 2 0]\n",
      " [0.0 1.0 0.0 ... 0.0 2 5]\n",
      " [0.0 1.0 0.0 ... 0.0 0 5]]\n"
     ]
    }
   ],
   "source": [
    "# Converte os dados de string para number gerando as categorias\n",
    "encoder = LabelEncoder()\n",
    "X[:,0] = encoder.fit_transform(X[:,0])\n",
    "X[:,1] = encoder.fit_transform(X[:,1])\n",
    "X[:,2] = encoder.fit_transform(X[:,2])\n",
    "X[:,3] = encoder.fit_transform(X[:,3])\n",
    "X[:,4] = encoder.fit_transform(X[:,4])\n",
    "X[:,5] = encoder.fit_transform(X[:,5])\n",
    "print(X)\n",
    "\n",
    "ct=ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0, 1, 2, 3])], remainder='passthrough')\n",
    "X=np.array(ct.fit_transform(X))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide o dataset em conjunto de treino e conjunto de teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35825, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converte os dados para uma mesma faixa de valores de 0 a 1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1120/1120 [==============================] - 1s 543us/step - loss: -1629.2527 - accuracy: 0.0000e+00\n",
      "Epoch 2/25\n",
      "1120/1120 [==============================] - 1s 524us/step - loss: -23747.8867 - accuracy: 0.0000e+00\n",
      "Epoch 3/25\n",
      "1120/1120 [==============================] - 1s 558us/step - loss: -90252.0547 - accuracy: 0.0000e+00\n",
      "Epoch 4/25\n",
      "1120/1120 [==============================] - 1s 592us/step - loss: -211913.2500 - accuracy: 0.0000e+00\n",
      "Epoch 5/25\n",
      "1120/1120 [==============================] - 1s 478us/step - loss: -395198.8438 - accuracy: 0.0000e+00\n",
      "Epoch 6/25\n",
      "1120/1120 [==============================] - 1s 481us/step - loss: -647259.1875 - accuracy: 0.0000e+00\n",
      "Epoch 7/25\n",
      "1120/1120 [==============================] - 1s 646us/step - loss: -975298.5000 - accuracy: 0.0000e+00\n",
      "Epoch 8/25\n",
      "1120/1120 [==============================] - 1s 578us/step - loss: -1385874.3750 - accuracy: 0.0000e+00\n",
      "Epoch 9/25\n",
      "1120/1120 [==============================] - 1s 598us/step - loss: -1887700.7500 - accuracy: 0.0000e+00\n",
      "Epoch 10/25\n",
      "1120/1120 [==============================] - 1s 566us/step - loss: -2484734.7500 - accuracy: 0.0000e+00\n",
      "Epoch 11/25\n",
      "1120/1120 [==============================] - 1s 607us/step - loss: -3184639.5000 - accuracy: 0.0000e+00\n",
      "Epoch 12/25\n",
      "1120/1120 [==============================] - 1s 609us/step - loss: -3997237.7500 - accuracy: 0.0000e+00\n",
      "Epoch 13/25\n",
      "1120/1120 [==============================] - 1s 629us/step - loss: -4929660.0000 - accuracy: 0.0000e+00\n",
      "Epoch 14/25\n",
      "1120/1120 [==============================] - 1s 576us/step - loss: -5988337.0000 - accuracy: 0.0000e+00\n",
      "Epoch 15/25\n",
      "1120/1120 [==============================] - 1s 593us/step - loss: -7180854.0000 - accuracy: 0.0000e+00\n",
      "Epoch 16/25\n",
      "1120/1120 [==============================] - 1s 561us/step - loss: -8509606.0000 - accuracy: 0.0000e+00\n",
      "Epoch 17/25\n",
      "1120/1120 [==============================] - 1s 493us/step - loss: -9982835.0000 - accuracy: 0.0000e+00\n",
      "Epoch 18/25\n",
      "1120/1120 [==============================] - 1s 468us/step - loss: -11608372.0000 - accuracy: 0.0000e+00\n",
      "Epoch 19/25\n",
      "1120/1120 [==============================] - 1s 489us/step - loss: -13399228.0000 - accuracy: 0.0000e+00\n",
      "Epoch 20/25\n",
      "1120/1120 [==============================] - 1s 578us/step - loss: -15352951.0000 - accuracy: 0.0000e+00\n",
      "Epoch 21/25\n",
      "1120/1120 [==============================] - 1s 529us/step - loss: -17486006.0000 - accuracy: 0.0000e+00\n",
      "Epoch 22/25\n",
      "1120/1120 [==============================] - 1s 483us/step - loss: -19796900.0000 - accuracy: 0.0000e+00\n",
      "Epoch 23/25\n",
      "1120/1120 [==============================] - 1s 482us/step - loss: -22296144.0000 - accuracy: 0.0000e+00\n",
      "Epoch 24/25\n",
      "1120/1120 [==============================] - 1s 638us/step - loss: -24984858.0000 - accuracy: 0.0000e+00\n",
      "Epoch 25/25\n",
      "1120/1120 [==============================] - 1s 646us/step - loss: -27875310.0000 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9e586d3400>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializa a ANN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adiciona a primeira camada\n",
    "regressor.add(Dense(units=6, activation='relu'))\n",
    "#regressor.add(Dropout(0.2))\n",
    "\n",
    "# Segunda camada\n",
    "regressor.add(Dense(units=6, activation='relu'))\n",
    "#regressor.add(Dropout(0.2))\n",
    "\n",
    "# Camada de saida\n",
    "regressor.add(Dense(units=1, activation='sigmoid'))\n",
    "#regressor.add(Dropout(0.2))\n",
    "\n",
    "# Quarta camada\n",
    "#regressor.add(GRU(units = 100))\n",
    "#regressor.add(Dropout(0.2))\n",
    "\n",
    "# Camada de saida\n",
    "#regressor.add(Dense(units = 9))\n",
    "2\n",
    "# Compila\n",
    "regressor.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Executa o treinamento\n",
    "regressor.fit(X_train, y_train, epochs = 25, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executa predição\n",
    "y_pred=regressor.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       ...,\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=(y_pred>0.5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...    0    0    0]\n",
      " [ 240    0    0 ...    0    0    0]\n",
      " [1449    0    0 ...    0    0    0]\n",
      " ...\n",
      " [   1    0    0 ...    0    0    0]\n",
      " [   1    0    0 ...    0    0    0]\n",
      " [   1    0    0 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
